\section{Introduction à l’apprentissage supervisé}
\label{chap4.section1}
Il y'a plusieurs types d'apprentissage dans l'apprentissage automatique, chacune avec ses propres familles d'algorithmes, mais le processus d'apprendre à partir d'exemples dont on connaît déjà les valeurs de la variable dépendante est ce que l'on appelle: \textbf{Apprentissage supervisé}.

Dans l'apprentissage supervisé, l'agent observe les paires entrée-sortie et apprend une fonction qui mappe l'entrée à la sortie. Par exemple, les entrées pourraient être des images de caméra, chacune accompagnée d'une étiquette (label) indiquant « bus » ou « piéton », etc. Le modèle doit apprendre une fonction qui, lorsqu'on lui donne une nouvelle image, prédit l'étiquette appropriée. En d'autres termes, étant donné des exemples de paires d'entrées-sorties \((x, y)\) générés par une fonction inconnue \(f\), où \(y = f(x)\), la tâche de l'apprentissage supervisé est de trouver une fonction \(h\) qui se rapproche si étroitement de la vraie fonction \(f\) que nous pourrions utiliser \(h\) pour prédire les comportements futurs de \(f\).

Les données utilisées pour trouver la fonction \(h\) sont appelées \textbf{"ensemble d’entraînement"}. Nous disons que le modèle d'apprentissage automatique généralise bien s'il prédit avec précision les étiquettes d'un autre ensemble de données inédites appelé \textbf{ensemble de test}.

Il existe essentiellement deux types de problèmes dans l'apprentissage supervisé selon le type d'étiquette: lorsque le résultat fait partie d'un ensemble fini de valeurs telles que ensoleillé/nuageux/pluvieux (prédire la météo) ou vrai/faux, le problème d'apprentissage est appelé \textbf{classification}. Lorsqu’il s’agit d’un nombre continu (comme la température de demain, mesurée soit sous forme d’entier, soit sous forme de nombre réel), le problème d’apprentissage porte le nom (certes étrange) de \textbf{régression}. Notre problème ici est de prédire quels clients vont faire défaut sur un prêt, c'est donc une \textbf{classification binaire}. 

Il existe également deux types de modèles d'apprentissage automatique: les modèles paramétriques et les modèles non paramétriques. Les modèles paramétriques (préférés pour les très grands ensembles de données) résument toutes les connaissances de l'ensemble de formation dans un ensemble relativement petit de paramètres ajustables (souvent appelés \textbf{poids}). Les exemples incluent les modèles de régression linéaire et les réseaux de neurones.
Les modèles non paramétriques (plus simple pour les ensembles de données plus petits) utilisent l'ensemble d'entraînement lui-même pour créer leur hypothèse, ils conservent souvent les données d'entraînement ou au moins une partie d'elles en mémoire et les utilisent à des fins de prédiction. Les exemples incluent l'algorithme des K plus proches voisins (\textbf{K-Nearest Neighbors}) et les arbres de décision. Il existe également des modèles qui combinent les deux philosophies, on pourrait les appeler: \textit{"Modèles Hybrides"}. Dans les prochaines sections on cherche à avoir une compréhension des différents algorithmes d'apprentissage utilisés dans mes recherche et du fonctionnement des modèles qu'ils créent.
\clearpage