\section{Sélection de prédicateurs}
\label{chap3.section2}
Après l'étape précédente de création de prédicateurs nous sommes passé d'un ensemble de près de 70 tables interconnectées contenant plusieurs type d'informations brutes à 128 tables indépendantes contenant 2526 prédicateurs potentiels et leur valeurs pour maximum 12.000 demandeurs (128 étant le nombre de partitions créées). Par contre, il est préférable de ne pas utiliser autant de prédicteurs pour entraîner des modèles, enfaîte c'est même une très mauvaise.

Comme je l'ai expliqué dans la précédente section, l'algorithme de synthèse approfondie de prédicateurs cherche à imiter l'intuition des data scientists en appliquant sequentiellement les mêmes fonctions mathématiques utilisées par ces derniers sur une relation ou une caracteristique brute lorsque les types des données sont compatibles avec ces opérations. Mais cette intuition n'est pas tout le temps correcte, des scientifiques expérimentés peuvent se tromper sur le pouvoir de prédiction d'un prédicateur potentiel alors un algorithme encore plus. Avec Deep Feature Synthesis nous misons sur la quantité et dans cette quantité il y'aura forcément quelques bon voir très bon prédicateurs, même souvent des prédicateurs auxquels un humain n'aurait pas du tout pu penser en raison de leur profondeur ou de leur nature mais une grande majorité des prédicateurs générés par l'algorithme seront redondants, peu informatifs ou même complètement absurdes.

Une étape importante qui suit systematiquement la création de prédicateurs est celle de \textbf{sélection de prédicateurs} (feature selection). Cette étape se caractérise par deux grandes approches inspirées de deux philosophies différentes, sélectionner les meilleurs ou éliminer les plus mauvais, les deux reviennent souvent au même résultat. La première méthode ou méthode d'emballage (\textit{wrapper method}) consiste à diviser les prédicateurs en sous groupes, entraîner un modèle avec chaque sous groupe et sélectionner le sous groupe surlequel a été entraîner le meilleur modèle, l'idée étant de donner une chance à chaque prédicateur potentiel et de laisser le modèle lui même déterminer et choisir les meilleurs. Cette méthode est généralement utilisée quand l'on possède un ensemble de prédicateurs que l'on consideère déjà comme bon (dont on connaît le pouvoir de prédiction) et qu'on veut réduire la taille et la complexité du modèle en sélectionnant les meilleurs sans trop affecter les perfomances du modèle. Elle possède par contre l'inconvénient du temps, si vous possédez beaucoup de prédicateur comme dans notre cas (qu'on ne peut pas tous appeler de bon prédicateurs en plus) cette méthode prendra le temps d'évaluer chaque sous groupe après entraînement ce qui va prendre beaucoup de temps, de plus si les sous groupes sont crées aléatoirement il est très probable qu'un sous groupe mélange des bons et mauvais prédicateurs et soit quand même sélectionné comme le meilleur.

La deuxième méthode ou méthode par filtrage (\textit{filter method}) a un principe de fonctionnement différent, éliminer les plus mauvais prédicateurs en fonction d'un ou plusieurs critères statistiques et arbitraires. Elle est beaucoup plus adaptée à notre situation car nécéssitant moins de temps et nous permettra de se débarasser des erreurs générées par l'algorithme. C'est donc celle que j'ai utilisé. Il est techniquement possible de combiner les deux méthodes, c'est-à-dire de filtrer les plus mauvais et ensuite de sélectionner les meilleurs des meilleurs, mais il existe aussi une méthode par filtrage qui peut être utiliser pour selectionner les meilleurs prédicateurs en se basant sur le gain d'information que j'ai utilisé et donc je n'ai pas juger nécéssaire d'utiliser d'autres méthodes d'emballage ensuite. Dans la prochaine sous-section je décris les techniques de filtrage que j'ai implémenté.

\subsection{Méthodes de filtrage}
\label{chap3.sec2.sub1}
J'ai implémenté quatre techniques de filtrage avec l'objectif de diminuer le nombre de prédicateurs de 2526 aux 100 plus informatifs (le nombre 100 a été choisi arbirairement et ne répond donc à aucune convention ou calcul préalable).

\begin{enumerate}
    \item \textbf{Supprimer les colonnes/prédicateurs avec beaucoup de valeurs manquantes}: Dans une entité, un attribut peut ne pas être strictement nécéssaire pour définir l'entité, c'est-à-dire qu'une instance de l'entité peut ne pas avoir de valeur pour cet attribut. Zéro étant considéré comme une valeur, il existe communément dans les bases de données une constante appélée \textbf{null ou none} représentant les cas où aucune valeur n'est applicable pour cette variable (signifiant que l'instance en question ne possède pas cet attribut). Par exemple, une personne pourrait avoir comme profession "none" (signifiant qu'elle est au chômage). Dans une tâche de prédiction maintenant si il y'a des prédicateurs pour lesquels la majorités des exemples ne possèdent pas de valeur, cela signifie que ce prédicateur n'est pas assez important pour déterminer la variable à prédire donc on peut s'en débarasser.
    \item \textbf{Supprimer les colonnes/prédicateurs avec une faible variance}: De manière analogue au cas précédent, un prédicateur qui ne varie pas d'un exemple à un autre ne peut nous aider à distinguer les exemples. Si presque tous les élèves dans une classe ont comme nom de famille \textbf{Traoré}, il ne me sert à rien de savoir que Traoré a triché à l'examen si je veux savoir qui a triché, ce qui est sûr c'est Traoré. La variance est une mésure statistique de la différence entre les valeurs dans une distribution. Plus précisément, elle mesure la distance entre chaque nombre de l'ensemble et la moyenne, et donc de tous les autres nombres de l'ensemble. Éliminer ces prédicateurs est un moyen de se débarasser des prédicateurs peu ou pas du tout infomatifs. La variance est le carré de l'écart type et est définie par la formule: \[V = \frac{\Sigma_{i=1}^N (x_i - \mu)^2}{N}\] où \(N\) est le nombre total d'exemples et \(\mu\) la moyenne de la distribution.
    \item \textbf{Supprimer les colonnes/prédicateurs avec une trop forte corrélation avec une autre colonne}: Il peut également arriver qu'un prédicateur soit informatif mais répétitif car un autre fournit presque excatement la même information. Par exemple il serait inutile d'avoir un prédicateur dont la valeur est égale au revenu mensuel d'un client si il y'a déjà un predicateur qui offre des informations sur les revenu hebdomadaire du client, il est sûr qu'un revenu hebdomadaire plus ou moins grand donnera  un revenu mensuel proportionnel. On dit que le revenu hebdomadaire a une corrélation absolue parfaite (égale à 1) avec le revenu mensuel car augmenter ou diminuer le premier va augmenter ou diminuer le second dans 100\% des cas. La corrélation est une mesure statistique qui exprime à quel point deux variables sont linéairement liées. Le coefficient de corrélation entre deux variables \(x\) et \(y\) est donnée par la formule: \[Corr = \frac{\Sigma_{i=1}^N (x_i - \bar{x}) \cdot (y_i - \bar{y})}{\sqrt{\Sigma_{i=1}^N (x_i - \bar{x})^2 \cdot \Sigma_{i=1}^N (y_i - \bar{y})^2}}\] où \(N\) est le nombre total d'exemples, \(\bar{x}\) la moyenne de la variable \(x\) et \(\bar{y}\) la moyenne de la variable \(y\).
    \item \textbf{Sélectionner les 100 plus informatifs prédicateurs}: Dans une tâche de prédiction tous les prédicateurs n'ont pas le même impact sur la variable à prédire. La corrélation linéaire pourrait être utilisée pour savoir quels prédicateurs a la plus grande importance, en calculant le coefficient de la relation linéaire entre chaque prédicateur et le target, celui qui a la plus grande corrélation serait le prédicateurs le plus informatif. Mais en pratique toutes les rélations entre les prédicateurs et la variable dépendante ne sont pas aussi simple que la corrélation, dans les ensemble de données plus élaborés les variables peuvent partager des rélations plus complexes qui ne sont même pas d'ordre linéaire. Un critère plus général serait le \textbf{gain d'information}. Le gain d'informations d'un prédicateur est une mesure de la capacité de ce prédicateur à distinguer les exemples, plus exactement à quel point connaître la valeur de ce prédicateur nous permet de connaître la valeur de la variable dépendante et il est calculé grâce à l'entropie. L'entropie est la grandeur fondamentale de la théorie de l'information, c'est une mesure de l'incertitude d'une variable aléatoire; plus il y a d’informations, moins il y a d’entropie. Le gain d'informations d'un attribut est calculé comme la différence entre l'entropie de l'ensemble des données avant que l'on considère cet attribut et l'entropie de l'ensemble de données une fois la valeur de l'attribut connue. \[IG (D, A) = H(D) - H(D | A)\] où \(H(D)\) est l'entropie de l'ensemble de données avant et \(H(D | A)\) est l'entropie pondérée après.
    En général, l'entropie d'une variable aléatoire \(V\) avec des valeurs \(v_i\) ayant une probabilité \(P(v_i)\) est définie comme: \[Entropy: H(V) = \Sigma_i P(v_i) \cdot log_2 (\frac{1}{P(v_i)}) = −\Sigma_i P(v_i) \cdot log_2 (P(v_i))\] Et l'entropie pondérée est donnée par la formule: \[H(D | A) = \Sigma_i w_i \cdot H(D_i)\] où \(w_i\) est le nombre d'exemples dans le sous-ensemble \(D_i\) par rapport à l'ensemble de données entier (\(w_i\) = nombre d'exemples où \(A = v_i\) / nombre total d'exemples dans \(D\)) et \(H(D_i)\) est l'entropie du sous-ensemble \(D_i\).
\end{enumerate}

\subsection{Implémentation}
\label{chap3.sec2.sub2}
J'ai écrit une fonction pour chacune des techniques expliquée ci dessus, toujours dans le même langage de programmation, un seuil a arbitrairement été choisi pour les trois premières techniques. En raison de taille de l'ensemble de données encore une fois, j'ai utilisé une stratégie simple, pour ne pas puiser mes ressources et augmenter le temps d'exécution du code, j'ai combiner les matrices de prédicateurs de 32 des 128 partitions soit à peu près 25\% des exemples et je n'ai appliquer les différentes fonctions que sur ce sous-ensemble. J'ai ensuite généraliser les résultats à l'ensemble de données entier en reportant les mêmes prédicateurs sélectionnés. Reduisant ainsi le nombre de prédicateurs de 2526 à 100, ce qui permettra d'accélérer les entraînements et de simplifier l'interprêtation des modèles (\cite{diarra2024featureselection}).

Quelques uns des prédicateurs sélectionnés sont: le niveau d’étude du demandeur, ses types de revenues, les langues qu’elle parle, les rôle qu’elle a occupés dans sa vie au niveau professionnel, son sexe, le nombre de demandes de prêts passés, le nombre de jours de retard de délai (s’il y’a eu retard), le mois, la saison et le jour de la semaine de la decision finale (si oui ou non le prêt lui avait été accordé), sa residences, ses charges financières etc... Ce nouvel ensemble de données a aussi été publié (\cite{diarra2024deep}).